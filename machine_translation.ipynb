{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "machine_translation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szkics/GerLangReconstruct/blob/main/machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlpoGrbJ0udr",
        "outputId": "e0cc0c15-5329-44b8-eb76-ad89f6604f6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPyVoMDb0vsM",
        "outputId": "3d1542ee-456a-4491-e270-571b263543cc"
      },
      "source": [
        "input_word_list = []\n",
        "target_word_list = []\n",
        "with open(\"/content/gdrive/MyDrive/gerlangreconstruct/german_english_dictionary.csv\") as f:\n",
        "    for line in f:\n",
        "      splitted_line = line.split(\",\")\n",
        "      input_word = splitted_line[0].lower()\n",
        "      input_word_to_append = ''.join(e for e in input_word if e.isalnum() and not e.isdigit())\n",
        "      input_word_list.append(input_word_to_append)\n",
        "      target_word = splitted_line[1].lower()\n",
        "      target_word_to_append = ''.join(e for e in target_word if e.isalnum() and not e.isdigit())\n",
        "      target_word_list.append(target_word_to_append)\n",
        "len(input_word_list)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skEfvykM0ytF",
        "outputId": "d4a825f1-54d3-472a-c918-9611da283a38"
      },
      "source": [
        "len(target_word_list)\n",
        "input_word_list = input_word_list[:1000]\n",
        "target_word_list = target_word_list[:1000]\n",
        "len(target_word_list)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW7wrDQT0q3o"
      },
      "source": [
        "import collections\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-mqkVEn0q3u",
        "outputId": "4a6ba86b-a508-40c2-d4c1-a5e743188980"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 8274619063317402697\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4KJpmBs0q3y",
        "outputId": "9d316ead-9de4-4699-c8cf-2f254e6422ef"
      },
      "source": [
        "# Load English data\n",
        "english_sentences = input_word_list #helper.load_data('data/small_vocab_en')\n",
        "# Load French data\n",
        "french_sentences = target_word_list#helper.load_data('data/small_vocab_fr')\n",
        "\n",
        "print('Dataset Loaded')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8ufJjmV0q31",
        "outputId": "a2c6b01c-265b-4e09-f976-12fa5022de8f"
      },
      "source": [
        "for sample_i in range(5):\n",
        "    print('German sample {}:  {}'.format(sample_i + 1, german_sentences[sample_i]))\n",
        "    print('French sample {}:  {}\\n'.format(sample_i + 1, english_sentences[sample_i]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English sample 1:  aale\n",
            "French sample 1:  eels\n",
            "\n",
            "English sample 2:  aalfell\n",
            "French sample 2:  eelskin\n",
            "\n",
            "English sample 3:  aalfischer\n",
            "French sample 3:  eeler\n",
            "\n",
            "English sample 4:  aalfänger\n",
            "French sample 4:  eeler\n",
            "\n",
            "English sample 5:  aalfänger\n",
            "French sample 5:  sniggler\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68cNoj0e0q37"
      },
      "source": [
        "def count_letters(input_word_list):\n",
        "  input_letter_counter = {}\n",
        "  alphabet = {}\n",
        "  unique_index = 0\n",
        "  for word in input_word_list:\n",
        "    for letter in list(word):\n",
        "      if letter in input_letter_counter:\n",
        "        input_letter_counter[letter] = input_letter_counter[letter] + 1\n",
        "      else:\n",
        "        input_letter_counter[letter] = 1\n",
        "      if letter not in alphabet:\n",
        "        alphabet[letter] = unique_index\n",
        "        unique_index = unique_index + 1\n",
        "  return input_letter_counter, alphabet\n",
        "\n",
        "input_letter_counter, input_alphabet = count_letters(german_sentences)\n",
        "target_letter_counter, output_alphabet = count_letters(english_sentences)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF0ZweGh25qS",
        "outputId": "4921a70a-3efe-4b0c-8530-29719b37d900"
      },
      "source": [
        "input_letter_counter"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 1583,\n",
              " 'b': 1305,\n",
              " 'c': 244,\n",
              " 'd': 376,\n",
              " 'e': 1260,\n",
              " 'f': 313,\n",
              " 'g': 622,\n",
              " 'h': 321,\n",
              " 'i': 420,\n",
              " 'j': 11,\n",
              " 'k': 180,\n",
              " 'l': 510,\n",
              " 'm': 121,\n",
              " 'n': 720,\n",
              " 'o': 149,\n",
              " 'p': 45,\n",
              " 'r': 596,\n",
              " 's': 354,\n",
              " 't': 513,\n",
              " 'u': 417,\n",
              " 'v': 28,\n",
              " 'w': 21,\n",
              " 'x': 2,\n",
              " 'y': 3,\n",
              " 'z': 51,\n",
              " 'ß': 10,\n",
              " 'ä': 85,\n",
              " 'é': 1,\n",
              " 'ö': 10,\n",
              " 'ü': 64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_tU_h7W5voo",
        "outputId": "e416f28f-997d-422b-a9a3-7b362494c3eb"
      },
      "source": [
        "input_alphabet"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 0,\n",
              " 'b': 22,\n",
              " 'c': 6,\n",
              " 'd': 21,\n",
              " 'e': 2,\n",
              " 'f': 3,\n",
              " 'g': 11,\n",
              " 'h': 7,\n",
              " 'i': 4,\n",
              " 'j': 16,\n",
              " 'k': 24,\n",
              " 'l': 1,\n",
              " 'm': 13,\n",
              " 'n': 10,\n",
              " 'o': 17,\n",
              " 'p': 15,\n",
              " 'r': 8,\n",
              " 's': 5,\n",
              " 't': 14,\n",
              " 'u': 19,\n",
              " 'v': 18,\n",
              " 'w': 20,\n",
              " 'x': 27,\n",
              " 'y': 25,\n",
              " 'z': 23,\n",
              " 'ß': 28,\n",
              " 'ä': 9,\n",
              " 'é': 29,\n",
              " 'ö': 12,\n",
              " 'ü': 26}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmn7M_nd0q3-"
      },
      "source": [
        "def tokenize(word, alphabet):\n",
        "  vectorized = []\n",
        "  for letter in list(word):\n",
        "    vectorized.append(alphabet[letter])\n",
        "  return vectorized\n",
        "\n",
        "tokenized_word = tokenize(\"fahrrad\", input_alphabet)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPWhUvWE7kq3",
        "outputId": "3ff2aeb5-f3cc-459e-b62f-72cd668de9a9"
      },
      "source": [
        "tokenized_word"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 0, 7, 8, 8, 0, 21]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQaXrc9e0q4A"
      },
      "source": [
        "def pad(x):\n",
        "  y = x\n",
        "  i = 0\n",
        "  number_of_zeros = 42-len(x)\n",
        "  while (i < number_of_zeros):\n",
        "      y.append(0)\n",
        "      i = i + 1\n",
        "  return y\n",
        "padded_word = pad(tokenized_word)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzN8Ywnw75uq",
        "outputId": "08b6556c-1deb-4c86-8414-55f989817212"
      },
      "source": [
        "padded_word"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3,\n",
              " 0,\n",
              " 7,\n",
              " 8,\n",
              " 8,\n",
              " 0,\n",
              " 21,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcOk0jJX0q4F"
      },
      "source": [
        "def preprocess(x, y, input_alphabet, target_alphabet):\n",
        "\n",
        "    preprocess_x = []\n",
        "    preprocess_y = []\n",
        "\n",
        "    for word in x:\n",
        "      preprocess_word = tokenize(word, input_alphabet)\n",
        "      preprocess_x.append(preprocess_word)\n",
        "\n",
        "    for word in y:\n",
        "      preprocess_word = tokenize(word, target_alphabet)\n",
        "      preprocess_y.append(preprocess_word)\n",
        "\n",
        "    pad_list_x = []\n",
        "    pad_list_y = []\n",
        "\n",
        "    for vectorized_word in preprocess_x:\n",
        "      pad_list_x.append(pad(vectorized_word))\n",
        "\n",
        "    for vectorized_word in preprocess_y:\n",
        "      pad_list_y.append(pad(vectorized_word))\n",
        "\n",
        "    preprocess_x = pad_list_x\n",
        "    preprocess_y = pad_list_y\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    # preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y\n",
        "\n",
        "preproc_german_sentences, preproc_english_sentences = preprocess(english_sentences, french_sentences, input_alphabet, output_alphabet)\n"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iq5mycTCAsT"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "preproc_english_sentences = preproc_english_sentences[:400]\n",
        "X_train = np.array(preproc_english_sentences)\n",
        "preproc_english_sentences = preproc_english_sentences[:400]\n",
        "y_train = np.array(preproc_english_sentences)\n",
        "# y_train = y_train.reshape(*y_train.shape, 1)\n",
        "X_dev = tf.constant([3.0, 1.0, 2.0])\n",
        "y_dev = tf.constant([0.0, 2.0, 1.0])"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uxmZdq3ODT0",
        "outputId": "6190830d-b3cb-4376-ac5c-d16e58aebfef"
      },
      "source": [
        "BATCH_SIZE, HIDDEN_SIZE = 32, 16\n",
        "NUM_ITERATIONS = 1\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    GRU(\n",
        "        HIDDEN_SIZE,\n",
        "        return_sequences=False,\n",
        "        input_shape=(42, 1),\n",
        "        unroll=True\n",
        "    )\n",
        ")\n",
        "model.add(Dense(42))\n",
        "model.add(Activation(\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    if (iteration % 10 == 0):\n",
        "      print(\"Iteration #: %d\" % (iteration))\n",
        "    model.fit(X_train[:, :, np.newaxis], y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Iteration #: 0\n",
            "13/13 [==============================] - 18s 8ms/step - loss: 282.7294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW7aMXusRp8P"
      },
      "source": [
        "pred = model.predict(X_train[:, :, np.newaxis], verbose=0)[0]"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q13GU6w0RzN-",
        "outputId": "e14944f7-ecdc-42d0-bb98-2e93f94612e1"
      },
      "source": [
        "pred"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.82555693e-01, 3.94929536e-02, 2.35430524e-01, 1.03304967e-01,\n",
              "       1.77975520e-01, 4.63540666e-02, 1.33609492e-02, 1.42012350e-03,\n",
              "       1.03003775e-04, 2.18653508e-06, 3.06819214e-09, 8.11677030e-15,\n",
              "       8.36036253e-19, 1.73900997e-25, 4.17283849e-36, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbmgJvFKPs31",
        "outputId": "aff6c5de-3b50-4636-b680-a114d2fafdb2"
      },
      "source": [
        "np.shape(X_train)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EZgFxBwQRX9",
        "outputId": "d8de1d57-a18b-4efc-e879-7bcc909a35fb"
      },
      "source": [
        "np.shape(X_train[:, :, np.newaxis])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 42, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL324zQHO2ci",
        "outputId": "37efe51f-7a2c-4d0f-a194-216d09b4fccd"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  1, ...,  0,  0,  0],\n",
              "       [ 0,  0,  1, ...,  0,  0,  0],\n",
              "       [ 0,  0,  1, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 8, 19, 15, ...,  0,  0,  0],\n",
              "       [ 8, 19, 15, ...,  0,  0,  0],\n",
              "       [15,  4, 12, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    }
  ]
}